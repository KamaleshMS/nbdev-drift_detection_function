{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# to set up auto reaload whenever changes are made in other modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Drift Function\n",
    "> This function helps to detect whether there is any drift in the data provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp Data_Drift_Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91637\\AppData\\Roaming\\Python\\Python38\\site-packages\\evidently\\analyzers\\__init__.py:3: UserWarning:\n",
      "\n",
      "analyzers are deprecated, use metrics instead\n",
      "\n",
      "C:\\Users\\91637\\AppData\\Roaming\\Python\\Python38\\site-packages\\evidently\\dashboard\\__init__.py:8: UserWarning:\n",
      "\n",
      "dashboards are deprecated, use metrics instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "import plotly.offline as py \n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from evidently.pipeline.column_mapping import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from evidently import ColumnMapping\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.dashboard import Dashboard\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.tests.base_test import generate_column_tests\n",
    "from evidently.test_preset import DataStabilityTestPreset, NoTargetPerformanceTestPreset\n",
    "from evidently.tests import *\n",
    "from evidently.test_preset import NoTargetPerformanceTestPreset\n",
    "from evidently.test_preset import DataQualityTestPreset\n",
    "from evidently.test_preset import DataStabilityTestPreset\n",
    "from evidently.test_preset import DataDriftTestPreset\n",
    "from evidently.test_preset import RegressionTestPreset\n",
    "from evidently.test_preset import MulticlassClassificationTestPreset\n",
    "from evidently.test_preset import BinaryClassificationTopKTestPreset\n",
    "from evidently.test_preset import BinaryClassificationTestPreset\n",
    "from datetime import datetime, timedelta\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from dateutil import parser\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def data_drift_test_selection(user_input, ref_data, cur_data):\n",
    "    \"\"\"\n",
    "    Selects the appropriate data drift test suite based on user input and runs the tests.\n",
    "\n",
    "    Parameters:\n",
    "        user_input (int): User input to select the type of data drift test suite.\n",
    "        ref_data (pd.DataFrame): Reference dataset.\n",
    "        cur_data (pd.DataFrame): Current dataset.\n",
    "\n",
    "    Returns:\n",
    "        TestSuite: The test suite containing the data drift tests.\n",
    "    \"\"\"\n",
    "    if (user_input == 1):\n",
    "        def basic_preset_tests_fun(user_input):\n",
    "            tests = TestSuite(tests=[\n",
    "                TestNumberOfColumnsWithMissingValues(),\n",
    "                TestNumberOfRowsWithMissingValues(),\n",
    "                TestNumberOfConstantColumns(),\n",
    "                TestNumberOfDuplicatedRows(),\n",
    "                TestNumberOfDuplicatedColumns(),\n",
    "                TestColumnsType(),\n",
    "                TestNumberOfDriftedColumns(),\n",
    "            ])\n",
    "            tests.run(reference_data=ref_data, current_data=cur_data)\n",
    "            return tests\n",
    "        \n",
    "        return basic_preset_tests_fun(user_input)\n",
    "\n",
    "    if (user_input == 2):\n",
    "        def data_stability_fun(user_input):\n",
    "            data_stability = TestSuite(tests=[\n",
    "                DataStabilityTestPreset(),\n",
    "            ])\n",
    "            data_stability.run(reference_data=ref_data, current_data=cur_data)\n",
    "            return data_stability\n",
    "        \n",
    "        return data_stability_fun(user_input)\n",
    "\n",
    "    elif (user_input == 3):\n",
    "        def data_quality_fun(user_input):\n",
    "            data_quality = TestSuite(tests=[\n",
    "                DataQualityTestPreset(),\n",
    "            ])\n",
    "            data_quality.run(reference_data=ref_data, current_data=cur_data)\n",
    "            return data_quality\n",
    "        \n",
    "        return data_quality_fun(user_input)\n",
    "\n",
    "    elif (user_input == 4):\n",
    "        def data_drift_fun(user_input):\n",
    "            data_drift = TestSuite(tests=[\n",
    "                DataDriftTestPreset(stattest='psi'),\n",
    "            ])\n",
    "            data_drift.run(reference_data=ref_data, current_data=cur_data)\n",
    "            return data_drift\n",
    "        \n",
    "        return data_drift_fun(user_input)\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid user input!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def detect_drift(X, window_size=\"NULL\"):\n",
    "    \"\"\"\n",
    "    Detects data drift in a dataset.\n",
    "\n",
    "    Parameters:\n",
    "        X (pd.DataFrame): Input dataset.\n",
    "        window_size (str or int): Window size for detecting data drift. Default is \"NULL\".\n",
    "\n",
    "    Yields:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame]: Current chunk and next chunk of data.\n",
    "    \"\"\"\n",
    "    drifts = []\n",
    "\n",
    "    def check_datetime_format(x):\n",
    "        try:\n",
    "            parser.parse(str(x), fuzzy=False, default=None)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    if window_size == \"NULL\":\n",
    "        # Determine window size based on data type\n",
    "        if X['Time'].apply(check_datetime_format).all():\n",
    "            X['Time'] = pd.to_datetime(X['Time'])\n",
    "\n",
    "            time_diff = pd.Timedelta(hours=24)\n",
    "            num_entries = []\n",
    "            for i in range(0, len(X), int(24 * 60 * 60 / time_diff.total_seconds())):\n",
    "                start_time = X['Time'].iloc[i]\n",
    "                end_time = start_time + time_diff\n",
    "                # count number of entries within chunk\n",
    "                num_entries.append(((X['Time'] >= start_time) & (X['Time'] < end_time)).sum())\n",
    "\n",
    "            mean_entries = sum(num_entries) / len(num_entries)\n",
    "            \n",
    "            window_size = int(mean_entries)\n",
    "            print(\"Using mean number of entries per 24-hour window as window size:\", window_size)\n",
    "        else:\n",
    "            # Use 100 as window size otherwise\n",
    "            window_size = 100\n",
    "            print(\"window size=100\")\n",
    "\n",
    "    else:\n",
    "        # Incase window size is provided by the user\n",
    "        window_size = window_size\n",
    "\n",
    "    num_chunks = int(np.ceil(X.shape[0] / window_size))\n",
    "    chunk_starts = np.arange(0, len(X), window_size)\n",
    "    chunk_ends = chunk_starts + window_size\n",
    "    curr_chunk = X[chunk_starts[0]:chunk_ends[0]]\n",
    "    next_chunk = X[chunk_starts[1]:chunk_ends[1]]\n",
    "\n",
    "    yield curr_chunk, next_chunk\n",
    "\n",
    "    for i in range(num_chunks - 2):\n",
    "        drift_detected = False\n",
    "\n",
    "        # Detect drift between curr_chunk and next_chunk\n",
    "        res = data_drift_test_selection(4, ref_data=curr_chunk, cur_data=next_chunk)\n",
    "        report_dict = res.as_dict()\n",
    "        if report_dict['tests'][0]['parameters']['features']['Electricity_load']['data_drift'] == 'Detected':\n",
    "            drift_detected = True\n",
    "\n",
    "        if drift_detected:\n",
    "            # Update curr_chunk and next_chunk for the next iteration\n",
    "            drifts.append((chunk_ends[i], chunk_starts[i+1]))\n",
    "            curr_chunk = next_chunk\n",
    "            if i+2 < num_chunks:\n",
    "                next_chunk = X[chunk_starts[i+2]:chunk_ends[i+2]]\n",
    "        else:\n",
    "            # Only update next_chunk for the next iteration\n",
    "            drifts.append((chunk_ends[i], chunk_starts[i+1]))\n",
    "            if i+2 < num_chunks:\n",
    "                next_chunk = X[chunk_starts[i+2]:chunk_ends[i+2]]\n",
    "\n",
    "        yield curr_chunk, next_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Dataset\n",
    "data = pd.read_csv('time_series_data_el.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_data_drift_detection():\n",
    "    \"\"\"\n",
    "    Runs the data drift detection on the dataset.\n",
    "    \"\"\"\n",
    "    res = detect_drift(data)\n",
    "    print(res)\n",
    "\n",
    "    for chunks in res:\n",
    "        for i, (curr_chunk, next_chunk) in enumerate(zip(chunks, chunks[1:])):\n",
    "            # Add assertions to check for expected results\n",
    "            assert isinstance(curr_chunk, pd.DataFrame), \"Current chunk should be a DataFrame\"\n",
    "            assert isinstance(next_chunk, pd.DataFrame), \"Next chunk should be a DataFrame\"\n",
    "            print(\"Current Chunk:\\n\", curr_chunk)\n",
    "            print(\"Next Chunk:\\n\", next_chunk)\n",
    "            print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object detect_drift>\n",
      "Using mean number of entries per 24-hour window as window size: 88\n",
      "Current Chunk:\n",
      "                   Time  Electricity_load\n",
      "0  2011-01-01 00:15:00              5.98\n",
      "1  2011-01-01 00:30:00              8.45\n",
      "2  2011-01-01 00:45:00              9.93\n",
      "3  2011-01-01 01:00:00              6.92\n",
      "4  2011-01-01 01:15:00              5.90\n",
      "..                 ...               ...\n",
      "83 2011-01-01 21:00:00             22.13\n",
      "84 2011-01-01 21:15:00             23.69\n",
      "85 2011-01-01 21:30:00             23.77\n",
      "86 2011-01-01 21:45:00             24.64\n",
      "87 2011-01-01 22:00:00             18.34\n",
      "\n",
      "[88 rows x 2 columns]\n",
      "Next Chunk:\n",
      "                    Time  Electricity_load\n",
      "88  2011-01-01 22:15:00             22.41\n",
      "89  2011-01-01 22:30:00             25.48\n",
      "90  2011-01-01 22:45:00             26.27\n",
      "91  2011-01-01 23:00:00             28.29\n",
      "92  2011-01-01 23:15:00             31.66\n",
      "..                  ...               ...\n",
      "171 2011-01-02 19:00:00             29.46\n",
      "172 2011-01-02 19:15:00             24.29\n",
      "173 2011-01-02 19:30:00             24.67\n",
      "174 2011-01-02 19:45:00             30.74\n",
      "175 2011-01-02 20:00:00             29.69\n",
      "\n",
      "[88 rows x 2 columns]\n",
      "------------------\n",
      "Current Chunk:\n",
      "                    Time  Electricity_load\n",
      "88  2011-01-01 22:15:00             22.41\n",
      "89  2011-01-01 22:30:00             25.48\n",
      "90  2011-01-01 22:45:00             26.27\n",
      "91  2011-01-01 23:00:00             28.29\n",
      "92  2011-01-01 23:15:00             31.66\n",
      "..                  ...               ...\n",
      "171 2011-01-02 19:00:00             29.46\n",
      "172 2011-01-02 19:15:00             24.29\n",
      "173 2011-01-02 19:30:00             24.67\n",
      "174 2011-01-02 19:45:00             30.74\n",
      "175 2011-01-02 20:00:00             29.69\n",
      "\n",
      "[88 rows x 2 columns]\n",
      "Next Chunk:\n",
      "                    Time  Electricity_load\n",
      "176 2011-01-02 20:15:00             28.41\n",
      "177 2011-01-02 20:30:00             24.54\n",
      "178 2011-01-02 20:45:00             26.94\n",
      "179 2011-01-02 21:00:00             26.76\n",
      "180 2011-01-02 21:15:00             31.85\n",
      "..                  ...               ...\n",
      "259 2011-01-03 17:00:00             37.63\n",
      "260 2011-01-03 17:15:00             29.47\n",
      "261 2011-01-03 17:30:00             30.37\n",
      "262 2011-01-03 17:45:00             30.72\n",
      "263 2011-01-03 18:00:00             36.57\n",
      "\n",
      "[88 rows x 2 columns]\n",
      "------------------\n",
      "Current Chunk:\n",
      "                    Time  Electricity_load\n",
      "176 2011-01-02 20:15:00             28.41\n",
      "177 2011-01-02 20:30:00             24.54\n",
      "178 2011-01-02 20:45:00             26.94\n",
      "179 2011-01-02 21:00:00             26.76\n",
      "180 2011-01-02 21:15:00             31.85\n",
      "..                  ...               ...\n",
      "259 2011-01-03 17:00:00             37.63\n",
      "260 2011-01-03 17:15:00             29.47\n",
      "261 2011-01-03 17:30:00             30.37\n",
      "262 2011-01-03 17:45:00             30.72\n",
      "263 2011-01-03 18:00:00             36.57\n",
      "\n",
      "[88 rows x 2 columns]\n",
      "Next Chunk:\n",
      "                    Time  Electricity_load\n",
      "264 2011-01-03 18:15:00             33.48\n",
      "265 2011-01-03 18:30:00             37.73\n",
      "266 2011-01-03 18:45:00             29.60\n",
      "267 2011-01-03 19:00:00             40.82\n",
      "268 2011-01-03 19:15:00             40.79\n",
      "..                  ...               ...\n",
      "347 2011-01-04 15:00:00             43.92\n",
      "348 2011-01-04 15:15:00             41.71\n",
      "349 2011-01-04 15:30:00             47.87\n",
      "350 2011-01-04 15:45:00             47.77\n",
      "351 2011-01-04 16:00:00             45.66\n",
      "\n",
      "[88 rows x 2 columns]\n",
      "------------------\n",
      "Current Chunk:\n",
      "                    Time  Electricity_load\n",
      "264 2011-01-03 18:15:00             33.48\n",
      "265 2011-01-03 18:30:00             37.73\n",
      "266 2011-01-03 18:45:00             29.60\n",
      "267 2011-01-03 19:00:00             40.82\n",
      "268 2011-01-03 19:15:00             40.79\n",
      "..                  ...               ...\n",
      "347 2011-01-04 15:00:00             43.92\n",
      "348 2011-01-04 15:15:00             41.71\n",
      "349 2011-01-04 15:30:00             47.87\n",
      "350 2011-01-04 15:45:00             47.77\n",
      "351 2011-01-04 16:00:00             45.66\n",
      "\n",
      "[88 rows x 2 columns]\n",
      "Next Chunk:\n",
      "                    Time  Electricity_load\n",
      "352 2011-01-04 16:15:00             40.18\n",
      "353 2011-01-04 16:30:00             42.71\n",
      "354 2011-01-04 16:45:00             40.93\n",
      "355 2011-01-04 17:00:00             43.46\n",
      "356 2011-01-04 17:15:00             46.72\n",
      "..                  ...               ...\n",
      "435 2011-01-05 13:00:00             43.95\n",
      "436 2011-01-05 13:15:00             44.27\n",
      "437 2011-01-05 13:30:00             43.51\n",
      "438 2011-01-05 13:45:00             53.46\n",
      "439 2011-01-05 14:00:00             46.31\n",
      "\n",
      "[88 rows x 2 columns]\n",
      "------------------\n",
      "Current Chunk:\n",
      "                    Time  Electricity_load\n",
      "352 2011-01-04 16:15:00             40.18\n",
      "353 2011-01-04 16:30:00             42.71\n",
      "354 2011-01-04 16:45:00             40.93\n",
      "355 2011-01-04 17:00:00             43.46\n",
      "356 2011-01-04 17:15:00             46.72\n",
      "..                  ...               ...\n",
      "435 2011-01-05 13:00:00             43.95\n",
      "436 2011-01-05 13:15:00             44.27\n",
      "437 2011-01-05 13:30:00             43.51\n",
      "438 2011-01-05 13:45:00             53.46\n",
      "439 2011-01-05 14:00:00             46.31\n",
      "\n",
      "[88 rows x 2 columns]\n",
      "Next Chunk:\n",
      "                    Time  Electricity_load\n",
      "440 2011-01-05 14:15:00             52.69\n",
      "441 2011-01-05 14:30:00             47.86\n",
      "442 2011-01-05 14:45:00             47.50\n",
      "443 2011-01-05 15:00:00             49.47\n",
      "444 2011-01-05 15:15:00             46.46\n",
      "..                  ...               ...\n",
      "523 2011-01-06 11:00:00             57.65\n",
      "524 2011-01-06 11:15:00             51.73\n",
      "525 2011-01-06 11:30:00             49.93\n",
      "526 2011-01-06 11:45:00             57.88\n",
      "527 2011-01-06 12:00:00             49.82\n",
      "\n",
      "[88 rows x 2 columns]\n",
      "------------------\n",
      "Current Chunk:\n",
      "                    Time  Electricity_load\n",
      "440 2011-01-05 14:15:00             52.69\n",
      "441 2011-01-05 14:30:00             47.86\n",
      "442 2011-01-05 14:45:00             47.50\n",
      "443 2011-01-05 15:00:00             49.47\n",
      "444 2011-01-05 15:15:00             46.46\n",
      "..                  ...               ...\n",
      "523 2011-01-06 11:00:00             57.65\n",
      "524 2011-01-06 11:15:00             51.73\n",
      "525 2011-01-06 11:30:00             49.93\n",
      "526 2011-01-06 11:45:00             57.88\n",
      "527 2011-01-06 12:00:00             49.82\n",
      "\n",
      "[88 rows x 2 columns]\n",
      "Next Chunk:\n",
      "                    Time  Electricity_load\n",
      "528 2011-01-06 12:15:00             51.46\n",
      "529 2011-01-06 12:30:00             52.35\n",
      "530 2011-01-06 12:45:00             53.10\n",
      "531 2011-01-06 13:00:00             48.39\n",
      "532 2011-01-06 13:15:00             48.50\n",
      "..                  ...               ...\n",
      "611 2011-01-07 09:00:00             57.42\n",
      "612 2011-01-07 09:15:00             63.50\n",
      "613 2011-01-07 09:30:00             63.27\n",
      "614 2011-01-07 09:45:00             66.21\n",
      "615 2011-01-07 10:00:00             62.27\n",
      "\n",
      "[88 rows x 2 columns]\n",
      "------------------\n",
      "Current Chunk:\n",
      "                    Time  Electricity_load\n",
      "528 2011-01-06 12:15:00             51.46\n",
      "529 2011-01-06 12:30:00             52.35\n",
      "530 2011-01-06 12:45:00             53.10\n",
      "531 2011-01-06 13:00:00             48.39\n",
      "532 2011-01-06 13:15:00             48.50\n",
      "..                  ...               ...\n",
      "611 2011-01-07 09:00:00             57.42\n",
      "612 2011-01-07 09:15:00             63.50\n",
      "613 2011-01-07 09:30:00             63.27\n",
      "614 2011-01-07 09:45:00             66.21\n",
      "615 2011-01-07 10:00:00             62.27\n",
      "\n",
      "[88 rows x 2 columns]\n",
      "Next Chunk:\n",
      "                    Time  Electricity_load\n",
      "616 2011-01-07 10:15:00             61.35\n",
      "617 2011-01-07 10:30:00             63.00\n",
      "618 2011-01-07 10:45:00             57.09\n",
      "619 2011-01-07 11:00:00             62.45\n",
      "620 2011-01-07 11:15:00             58.74\n",
      "621 2011-01-07 11:30:00             57.34\n",
      "622 2011-01-07 11:45:00             55.03\n",
      "623 2011-01-07 12:00:00             55.42\n",
      "624 2011-01-07 12:15:00             56.55\n",
      "625 2011-01-07 12:30:00             59.36\n",
      "626 2011-01-07 12:45:00             58.43\n",
      "627 2011-01-07 13:00:00             57.35\n",
      "628 2011-01-07 13:15:00             59.26\n",
      "629 2011-01-07 13:30:00             69.89\n",
      "630 2011-01-07 13:45:00             60.57\n",
      "631 2011-01-07 14:00:00             69.65\n",
      "632 2011-01-07 14:15:00             55.25\n",
      "633 2011-01-07 14:30:00             55.65\n",
      "634 2011-01-07 14:45:00             66.84\n",
      "635 2011-01-07 15:00:00             54.47\n",
      "636 2011-01-07 15:15:00             67.93\n",
      "637 2011-01-07 15:30:00             58.61\n",
      "638 2011-01-07 15:45:00             59.44\n",
      "639 2011-01-07 16:00:00             61.80\n",
      "640 2011-01-07 16:15:00             65.85\n",
      "641 2011-01-07 16:30:00             60.27\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the data drift detection.\n",
    "    \"\"\"\n",
    "    run_data_drift_detection()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
