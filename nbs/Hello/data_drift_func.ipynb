{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0857ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd60014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25eeb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6266d474",
   "metadata": {},
   "source": [
    "## Data Drift Function\n",
    "> This function helps in detecting any drift in the data using evidently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d368b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91637\\AppData\\Roaming\\Python\\Python38\\site-packages\\evidently\\analyzers\\__init__.py:3: UserWarning:\n",
      "\n",
      "analyzers are deprecated, use metrics instead\n",
      "\n",
      "C:\\Users\\91637\\AppData\\Roaming\\Python\\Python38\\site-packages\\evidently\\dashboard\\__init__.py:8: UserWarning:\n",
      "\n",
      "dashboards are deprecated, use metrics instead\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "import plotly.offline as py \n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from evidently.pipeline.column_mapping import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from evidently import ColumnMapping\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.dashboard import Dashboard\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.tests.base_test import generate_column_tests\n",
    "from evidently.test_preset import DataStabilityTestPreset, NoTargetPerformanceTestPreset\n",
    "from evidently.tests import *\n",
    "from evidently.test_preset import NoTargetPerformanceTestPreset\n",
    "from evidently.test_preset import DataQualityTestPreset\n",
    "from evidently.test_preset import DataStabilityTestPreset\n",
    "from evidently.test_preset import DataDriftTestPreset\n",
    "from evidently.test_preset import RegressionTestPreset\n",
    "from evidently.test_preset import MulticlassClassificationTestPreset\n",
    "from evidently.test_preset import BinaryClassificationTopKTestPreset\n",
    "from evidently.test_preset import BinaryClassificationTestPreset\n",
    "from datetime import datetime, timedelta\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from dateutil import parser\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b50a3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def data_drift_test_selection(user_input, ref_data, cur_data):\n",
    "    \"\"\"\n",
    "    Perform the selected data drift test suite on the reference data and current data.\n",
    "\n",
    "    Parameters:\n",
    "        user_input (int): User input to select the data drift test suite.\n",
    "        ref_data (pd.DataFrame): Reference data.\n",
    "        cur_data (pd.DataFrame): Current data.\n",
    "\n",
    "    Returns:\n",
    "        TestSuite: Test suite object containing the results of the data drift tests.\n",
    "\n",
    "    \"\"\"\n",
    "    if user_input == 1:\n",
    "        def basic_preset_tests_fun(user_input):\n",
    "            tests = TestSuite(tests=[\n",
    "                TestNumberOfColumnsWithMissingValues(),\n",
    "                TestNumberOfRowsWithMissingValues(),\n",
    "                TestNumberOfConstantColumns(),\n",
    "                TestNumberOfDuplicatedRows(),\n",
    "                TestNumberOfDuplicatedColumns(),\n",
    "                TestColumnsType(),\n",
    "                TestNumberOfDriftedColumns(),\n",
    "            ])\n",
    "            tests.run(reference_data=ref_data, current_data=cur_data)\n",
    "            return tests\n",
    "\n",
    "        return basic_preset_tests_fun(user_input)\n",
    "\n",
    "    elif user_input == 2:\n",
    "        def data_stability_fun(user_input):\n",
    "            data_stability = TestSuite(tests=[\n",
    "                DataStabilityTestPreset(),\n",
    "            ])\n",
    "            data_stability.run(reference_data=ref_data, current_data=cur_data)\n",
    "            return data_stability\n",
    "\n",
    "        return data_stability_fun(user_input)\n",
    "\n",
    "    elif user_input == 3:\n",
    "        def data_quality_fun(user_input):\n",
    "            data_quality = TestSuite(tests=[\n",
    "                DataQualityTestPreset(),\n",
    "            ])\n",
    "            data_quality.run(reference_data=ref_data, current_data=cur_data)\n",
    "            return data_quality\n",
    "\n",
    "        return data_quality_fun(user_input)\n",
    "\n",
    "    elif user_input == 4:\n",
    "        def data_drift_fun(user_input):\n",
    "            data_drift = TestSuite(tests=[\n",
    "                DataDriftTestPreset(stattest='psi'),\n",
    "            ])\n",
    "            data_drift.run(reference_data=ref_data, current_data=cur_data)\n",
    "            return data_drift\n",
    "\n",
    "        return data_drift_fun(user_input)\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid user input!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2294a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def detect_drift(X, window_size=\"NULL\"):\n",
    "    \"\"\"\n",
    "    Detect data drift in a dataset.\n",
    "\n",
    "    Parameters:\n",
    "        X (pd.DataFrame): Input dataset.\n",
    "        window_size (str or int): Size of the sliding window for drift detection. \n",
    "                                  If \"NULL\", the window size is automatically determined based on the data.\n",
    "\n",
    "    Yields:\n",
    "        tuple: Tuple containing the current chunk and the next chunk.\n",
    "\n",
    "    \"\"\"\n",
    "    drifts = []\n",
    "    def check_datetime_format(x):\n",
    "        try:\n",
    "            parser.parse(str(x), fuzzy=False, default=None)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    if window_size == \"NULL\":\n",
    "        # Determine window size based on data type\n",
    "        if X['Time'].apply(check_datetime_format).all():\n",
    "            X['Time'] = pd.to_datetime(X['Time'])\n",
    "\n",
    "            # Use mean number of entries per 24-hour window as window size if time is in datetime format\n",
    "            time_diff = pd.Timedelta(hours=24)\n",
    "            num_entries = []\n",
    "            for i in range(0, len(X), int(24 * 60 * 60 / time_diff.total_seconds())):\n",
    "                start_time = X['Time'].iloc[i]\n",
    "                end_time = start_time + time_diff\n",
    "                # count number of entries within chunk\n",
    "                num_entries.append(((X['Time'] >= start_time) & (X['Time'] < end_time)).sum())\n",
    "\n",
    "            mean_entries = sum(num_entries) / len(num_entries)\n",
    "\n",
    "            window_size = int(mean_entries)\n",
    "            print(\"Using mean number of entries per 24-hour window as window size:\", window_size)\n",
    "\n",
    "\n",
    "        else:\n",
    "            # Use 100 as window size otherwise\n",
    "            window_size = 100\n",
    "            print(\"Window size = 100\")\n",
    "\n",
    "    else:\n",
    "        # In case window size is provided by the user\n",
    "        window_size = int(window_size)\n",
    "\n",
    "\n",
    "    num_chunks = int(np.ceil(X.shape[0] / window_size))\n",
    "    chunk_starts = np.arange(0, len(X), window_size)\n",
    "    chunk_ends = chunk_starts + window_size\n",
    "    curr_chunk = X[chunk_starts[0]:chunk_ends[0]]\n",
    "    next_chunk = X[chunk_starts[1]:chunk_ends[1]]\n",
    "\n",
    "    yield curr_chunk, next_chunk\n",
    "\n",
    "    for i in range(num_chunks - 2):\n",
    "        drift_detected = False\n",
    "\n",
    "        # Detect drift between curr_chunk and next_chunk\n",
    "        res = data_drift_test_selection(4, ref_data=curr_chunk, cur_data=next_chunk)\n",
    "        report_dict = res.as_dict()\n",
    "        if report_dict['tests'][0]['parameters']['features']['Electricity_load']['data_drift'] == 'Detected':\n",
    "            drift_detected = True\n",
    "\n",
    "        if drift_detected:\n",
    "            # Update curr_chunk and next_chunk for the next iteration\n",
    "            drifts.append((chunk_ends[i], chunk_starts[i+1]))\n",
    "            curr_chunk = next_chunk\n",
    "            if i+2 < num_chunks:\n",
    "                next_chunk = X[chunk_starts[i+2]:chunk_ends[i+2]]\n",
    "        else:\n",
    "            # Only update next_chunk for the next iteration\n",
    "            drifts.append((chunk_ends[i], chunk_starts[i+1]))\n",
    "            if i+2 < num_chunks:\n",
    "                next_chunk = X[chunk_starts[i+2]:chunk_ends[i+2]]\n",
    "\n",
    "        yield curr_chunk, next_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7999c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def process_drift(drift):\n",
    "    \"\"\"\n",
    "    Process the detected drift.\n",
    "\n",
    "    Parameters:\n",
    "        drift (tuple): Tuple containing the start and end index of the drift.\n",
    "\n",
    "    \"\"\"\n",
    "    start, end = drift\n",
    "    print(f\"Drift detected from index {start} to {end}\")\n",
    "\n",
    "    # Perform actions to handle the detected drift\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def run_data_drift_detection():\n",
    "    \"\"\"\n",
    "    Run the data drift detection process.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    data = pd.read_csv(\"time_series_data_el.csv\")\n",
    "    \n",
    "    # Perform data drift detection for the current chunk and next chunk\n",
    "    for curr_chunk, next_chunk in detect_drift(data):\n",
    "        for drift in detect_drift(curr_chunk, next_chunk):\n",
    "            # Process the drift data\n",
    "            process_drift(drift)\n",
    "\n",
    "    # Update the reference data for the next iteration\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422931e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mean number of entries per 24-hour window as window size: 88\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m     run_data_drift_detection()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 12\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [9], line 8\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    Main function to run the data drift detection process.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mrun_data_drift_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [8], line 11\u001b[0m, in \u001b[0;36mrun_data_drift_detection\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Perform data drift detection for the current chunk and next chunk\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m curr_chunk, next_chunk \u001b[38;5;129;01min\u001b[39;00m detect_drift(data):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m drift \u001b[38;5;129;01min\u001b[39;00m detect_drift(curr_chunk, next_chunk):\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;66;03m# Process the drift data\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         process_drift(drift)\n",
      "Cell \u001b[1;32mIn [6], line 23\u001b[0m, in \u001b[0;36mdetect_drift\u001b[1;34m(X, window_size)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mwindow_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNULL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Determine window size based on data type\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(check_datetime_format)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m     26\u001b[0m         X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\users\\91637\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__nonzero__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1528\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe truth value of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1529\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1530\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# Cell 6\n",
    "\n",
    "# export\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the data drift detection process.\n",
    "    \"\"\"\n",
    "    run_data_drift_detection()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7308db66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da32501f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c510386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06693b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
